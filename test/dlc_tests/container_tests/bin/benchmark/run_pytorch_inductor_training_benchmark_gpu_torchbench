#!/bin/bash

PYTHON_VERSION=$(python -c 'import sys; print(sys.version_info[0])' | tr -d "'")
if [ "$PYTHON_VERSION" -eq 2 ]
then
  exit 0
fi
HOME_DIR=/test/benchmark
BIN_DIR=${HOME_DIR}/bin
LOG_DIR=${HOME_DIR}/logs

mkdir -p ${HOME_DIR}
mkdir -p ${BIN_DIR}
mkdir -p ${LOG_DIR}

python -c "import sys;
assert sys.version_info < (3, 7);"
PYTHON_VERSION_CHECK=`echo $?`

set -e
cd $BIN_DIR
rm -rf $BIN_DIR/pytorch
git clone https://github.com/pytorch/pytorch.git --branch v2.0.0 --single-branch --depth 1  $BIN_DIR/pytorch


pip install -U numpy
pip install gitpython
pip install tabulate==0.9.0

TRAINING_LOG=${LOG_DIR}/pytorch_inductor_torchbench_benchmark.log

# install torchdata and torchtext before installing torchbench
git clone --branch v0.6.0 https://github.com/pytorch/data.git $BIN_DIR/pytorch/torchdata
cd $BIN_DIR/pytorch/data
pip install .

git clone https://github.com/pytorch/text $BIN_DIR/pytorch/torchtext 
cd $BIN_DIR/pytorch/torchtext
git submodule update --init --recursive
FORCE_CUDA=1 python setup.py clean install

git clone https://github.com/pytorch/benchmark $BIN_DIR/pytorch/benchmark
cd $BIN_DIR/pytorch/benchmark
python install.py

if [[$1 -eq "p3.2xlarge" || $1 -eq "g4dn.4xlarge"]]; then
    sed -i "s/BATCH_SIZE_KNOWN_MODELS\[model_name\] = batch_size/BATCH_SIZE_KNOWN_MODELS[model_name] = batch_size \/ 4 if batch_size >= 4 else 1/g" $BIN_DIR/pytorch/benchmarks/dynamo/torchbench.py
elif [[$1 -eq "g5.4xlarge"]]; then
    sed -i "s/BATCH_SIZE_KNOWN_MODELS\[model_name\] = batch_size/BATCH_SIZE_KNOWN_MODELS[model_name] = batch_size \/ 4 if batch_size >= 4 else 1/g" $BIN_DIR/pytorch/benchmarks/dynamo/torchbench.py
else
    echo "No need to adjust batch size since we are using p4d.24xlarge."
fi

rm -rf $BIN_DIR/pytorch/torchbench_logs
mkdir -p $BIN_DIR/pytorch/torchbench_logs
python $BIN_DIR/pytorch/benchmarks/dynamo/torchbench.py --performance --amp -dcuda --output=torchbench_logs/inductor_torchbench_amp_training_cuda_performance.csv --training --inductor --output-directory=$BIN_DIR/pytorch/ --no-skip --dashboard -x GPTJForCausalLM -x Reformer -x GPTJForQuestionAnswering -x GPTNeoForSequenceClassification -x BlenderbotForConditionalGeneration -x GPTNeoForCausalLM --cold-start-latency 
python $BIN_DIR/pytorch/benchmarks/dynamo/torchbench.py --accuracy --amp -dcuda --output=torchbench_logs/inductor_torchbench_amp_training_cuda_accuracy.csv --training --inductor --output-directory=$BIN_DIR/pytorch/ --no-skip --dashboard -x GPTJForCausalLM -x Reformer -x GPTJForQuestionAnswering -x GPTNeoForSequenceClassification -x BlenderbotForConditionalGeneration -x GPTNeoForCausalLM --cold-start-latency > $TRAINING_LOG 2>&1


RETURN_VAL=`echo $?`
set -e

if [ ${RETURN_VAL} -eq 0 ]; then
    echo "Training Torchbench Complete using PyTorch Inductor."
else
    echo "Training Torchbench Failed using PyTorch Inductor."
    cat $TRAINING_LOG
    exit 1
fi

python $HOME_DIR/read_upload_benchmarking_results.py -dir $BIN_DIR/pytorch/torchbench_logs \
       -model_suite torchbench -precision amp -instance_type $1

exit 0